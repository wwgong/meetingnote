#Meeting note for meeting on 09/26/2011.


# Procedure “Transfer” messages #

## Different sender? ##
```
 [SENDING MPPM] MULTI_PARTITION_PARTICIPANT (FROM 1 TO -1)
 [SENDING ITM] INITITATE_TASK (FROM 0 TO 1) FOR TXN
```

These are the messages sent by initiator to participants of a MultiPartitionQuery. Because in the ITM.toString(), FROM comes from field m\_initiatorSiteId, but in the MPPM.toString(), FROM comes from field m\_coordinatorSiteId. So, two FROMs are different.

## Two transactions for one stored procedure? ##
~~Based on the book “Using VoltDB”, these two concepts are the same in VoltDB, stored procedure succeeds or rollbacks as a whole. However, each SQL statement is treated as one internal transaction
SnapShot system procedure can’t be called inside stored procedure, so it won’t cause inconsistent states.
Although I can’t see relation among different transactions in one stored procedure (from fields and values of parameters/arguments) yet, I think I will dig the invocations (StoredProcedureInvocation, ProcedureInvocation) deeper because I think it’s the most possible place.~~


# Run escrow example with sites-per-host more than 2 #
```
System: 
Processor 2.4GHz Intel Core 2 Duo
Memory: 4GB
```

Based on the book “Using VoltDB”, we can use up to 4 partitions, and the optimal setting should be 3 (3/4 of the number of the CPUs).  However, I can’t run VoltDB with sites-per-host more than 2 inside Eclipse.

```
SitesPerHost = 4
```

The error msg is:
```
   java.lang.OutOfMemoryError: Direct buffer memory
```

ExecutionEngineJNI:
```
10485760 + 20971520 + 2048 = 30MB
SnapshotSiteProcessor: 12 SnapShotBuffers
	12 * 2129919 = 25559028 = 24MB
Total: (30 + 24) * 4 = 216MB
```

Eclipse argument:
```
-vmargs -Xmx3072M (3GB memory)
```

System Monitor: eclipse only uses 300MB memory.

While doing TPCC benchmark, I am able to start VoltDB server with SitesPerHost = 4.

# TPCC benchmark #

  * “tpcc\_build.xml” under tests/frontend/org/voltdb/benchmark/tpcc doesn’t work. The path parameters in it are not correct. After correcting them, it still can’t compile.

## Steps to build TPC-C benchmark ##
  * type command “ant voltbin” in voltdb home dir
  * add a target “tpcc” in “build.xml”
```
<target name="tpcc" description="Call the standard benchmark target configured to use test cluster.">
    <antcall target="benchmark" inheritAll='true'>
    			 <!-- Local mode or remote mode -->
    	 <param name="local" value="true" />
        <!-- Number of servers in your cluster -->
        <param name="hostcount" value="1"/>
        <!-- Number of VoltDB partitions per server -->
        <param name="sitesperhost" value="2"/>
        <!-- Number of warehouses for the benchmark, set equal to the number of unique partitions, as in ((hostcount * sitesperhost) / (kfactor + 1)) -->
        <param name="warehouses" value="2"/>
        <!-- Set less than number of warehouses, used to load warehouses in parallel (12 or less) -->
        <param name="loadthreads" value="1" />
        <!-- k-safety value for the benchmark -->
        <param name="kfactor" value="0"/>
        <!-- number of client machines for benchmark -->
        <param name="clientcount" value="1"/>
        <!-- number of client processes per client machine (usually left at 1) -->
        <param name="processesperclient" value="1"/>
        <!-- duration, in milliseconds, for benchmark run (60,000 = 1 minute) -->
        <param name="duration" value="60000" />
        <!-- list of all server hostnames for benchmark -->
        <param name="host1" value="localhost"/>
        <!-- list of all client hostnames for benchmark -->
        <param name="clienthost1" value="localhost"/>
        <!-- JVM heap size for servers -->
        <param name="volt.server.memory" value="1024"/>
        <!-- JVM heap size for clients -->
        <param name="volt.client.memory" value="512"/>
    </antcall>
</target>
```

  * type command “ant tpcc”
    * Problem: main process waits client process to be ready forever.
      * BenchmarkController.java
```
	        while (m_clientsNotReady.get() > 0)
                      Thread.yield();  
```
      * ClientStatusThread waits next available client response via
```
                m_clientPSM.nextBlocking()
```
      * However, there is no element contained in member
```
                m_output (type: LinkedBlockingQueue<OutputLine>) in the m_clientPSM (type: ProcessSetManager)
```
> > > > , so the main process is waiting forever.

## Procedure “neworder” in TPCC ##
  * a.	All tables are partitioned on W\_ID based on “tpcc-ddl.sql” and TPCCProjectBuilder.java.

  * b.	TPCCSimulation.java: doNewOrder()
```
boolean remote = false;
```

> > So,
```
supply_w_id[i] == warehouse_id 
```
> > > which means no cross partition query.

  * c.	neworder.java: run()
```
isAllLocal == true
```

> > because it’s initialized to be TRUE and since supply\_w\_id is set to be the same as warehouse\_id in step b, all sql queries in this function are executed on the same site. Thus, even it sends queries multiple times, all queries are SinglePartitionQuery.


# JDBC example #
  * Different deployment.xml syntax format for 1.3.6 and 2.0
In voltdb-2.0, attribute “leader” is no longer under “cluster” but specified in the build.xml or command line.
  * Use the same escrow example, and try to retrieve data via JDBC.

```
import java.sql.*;
import java.io.*;

public class BasicJDBCDemo
{
	Connection conn;
	
	public static void main(String[] args)
	{
		
        String driver = "org.voltdb.jdbc.Driver";
        String url = "jdbc:voltdb://localhost:21212";
		
		try
		{
			System.out.println("Starting...");
			Class.forName(driver);
			
			System.out.println("Connecting database...");
            		Connection conn = DriverManager.getConnection(url);
			
			System.out.println("Start test...");
						
			System.out.println("[OUTPUT FROM SELECT]");
			String query = "SELECT ACCTID, BALANCE FROM ACCOUNT";

			ResultSet rs = st.executeQuery(query);
			while (rs.next())
			{
				int s = rs.getInt("ACCTID");
				int n = rs.getInt("BALANCE");
				System.out.println(s + "   " + n);
			}
			
			st.close();
			conn.close();
		} catch (Exception ex) {ex.printStackTrace();}
	}
}
```

  * Doesn’t support CallableStatement, can’t control transaction (no start/commit/rollback, always auto-commit), and only non-sensitive and not updated ResultSet (TYPE\_SCROLL\_INSENSITIVE & CONCUR\_READ\_ONLY) supported.

  * Since all queries submitted via JDBC are executed as AdHoc queries in VoltDB, all of them are treated as MultiPartitionQuery even if they might be SinglePartitionQuery (eg. INSERT).

  * Problem: debugger (Eclipse) can’t stop on JDBC layer though I set many breakpoints there.



# Adding a new system procedure #

  * @SystemCatalog can return all catalog data of current running database, and @UpdateApplicationCatalog can real-time update catalog data. And we could access ExecutionSite instance, ExecutionEngine instance, and etc via SystemProcedureExecutionContext and VoltDB instance as well.

  * If we want to implement a system procedure similar to “mysql\_insert\_id()”, it’s possible to access table content (if auto-increment implemented via SELECT-UPDATE mode) or access a in-memory counter (just like mysql\_insert\_id() does, when system starts and reloads the database, the initial value is loaded, if no database reloaded, initialize this counter to 0).

  * API: ClientResponse client.callProcedure(“@AutoIncrementId”, String table\_name) Returns newest id value for the auto-increment field in the specified table.

  * Implementation: in the run(), creates a MultiParitionQuery, composes and sends MultiParitionParticipantTask message to all other nodes (current node is the coordinator node because we could ask current node to act as ES to process initiate task), and then let current node to process initiate task.

 
# How to Compile a Stored Procedure #

In the application deployment phase, system compiles a bunch of stored procedures (.java file), a schema file (.sql), and a project definition file (.xml) to build the application catalog (.jar file), and when system running the application, it will need the catalog and the deployment file.

Project definition file (.xml) has following three main attributes:
```
	database / schemas / schema (path)
	database / procedures / procedure (class)
	database / partitions / partition (table, column)
```
and the full list of elements and attributes is here: http://community.voltdb.com/docs/UsingVoltDB/ProjDefStructure

Run VoltCompiler (focus on Procedure):
```
	arguments: input – project definition .xml file
			   output – application catalog .jar file
```

  * a.	VoltCompile.compileCatalog() - parse .xml file to generate a ProjectType variable representing current project, and its main element is of DatabaseType corresponding to attribute “database” in the .xml file

  * b.	VoltCompile.compileDatabaseNode()
    * •	Further parse information in DatabaseType.
    * •	for each procedure of type ProcedureType.Procedure (raw type representing procedure described in the .xml file, element of DatabaseType), create one ProcedureDescriptor type variable with parsed information;
    * •	Start a new hsqldb and build the database using DDLs specified in the schema files.
    * •	Generate auto-crud procedure descriptors, i.e. if the primary keys include partitioned column, create INSERT, SELECT, DELETE, and UPDATE on it.
    * •	For each ProcedureDescriptor, compile it --

  * c.	ProcedureCompile.compileSingleStmtProcedure(): for auto-crud procedure and single statement procedure specified in the project .xml file.

  * d.	ProcedureCompile. compileJavaProcedure (): for procedure defined in a .java file
    * •	Create type Procedure data, which represents a stored procedure (transaction) in the system. For “@ProcInfo” annotation, record it’s single-partition or multi-partition, if it’s single-partitioned, verify “partitionInfo” and store it; retrieve and check SQL statements.
    * •	Parse “partitionInfo”: only valid when the column is of type (long, integer, short, byte, string), and specified as partition column in the table.

For one procedure, it’s first represented by type ProcedureType.Procedure while parsing project definition file, then represented by type ProcedureDescriptor when creating application catalog, and stored as type Procedure in the catalog and further generate VoltProcedure type instance used in run-time.


# Escrow Procedure’s  “PartitionInfo” #

Since some escrow type transactions are of type multi-partition (i.e. example of transferring between accounts involves 2 sites), it can’t benefit from current “@ProcInfo” annotation, especially the data of element “partitionInfo”. However, this type of escrow transaction usually query based on the same partition column with different value.

If extending “@ProcInfo” annotation to:
```
	@ProcInfo(
			partitionInfo = "ACCOUNT.ACCTID: 0, 2",
			singlePartition = false
			escrowMultiPartition = true
        )
```
with “partitionInfo” still contains only one partition column, we can try to get partition information while parsing the client request.

  * getPartitionForProcedure(): use the mapping of parameters between Procedure and   StoredProcedureInvocation, and the partitionIndex to locate partition.

  * Place need to change:
```
	Procedure
              int m_partitionparameter → ArrayList<Integer> m_partitionparameter
	ProcedureCompile
              compileJavaProcedure()
              parsePartitionInfo()
	ClientInterface: 
              handleRead()
              getPartitionForProcedure(int partitionIndex, StoredProcedureInvocation task) → getPartitionsForProcedure(Arraylist<Integer> partitionIndice, StoredProcedureInvocation task)
```



# Split resursableRun() to send out fragments asap #

  * The routine to create fragments from InitiateTaskMessage for a multi-partition transaction:
```
MultiPartitionParticipantTxnState.doWork() 
–> MultiPartitionParticipantTxnState.initiateProcedure() 
–> ExecutionSite.processInititeTask() 
–> VoltProcedure.call()
–> VoltProcedure.voltExecuteSQL() 
–> VoltProcedure.executeQueriesInABatch() 
–> VoltProcedure.slowPath()
–> MultiPartitionParticipantTxnState.createLocalFragmentWork() or createAllParticipatingFragmentWork()
```

And the declaration of a FragmentTaskWork is:
```
FragmentTaskMessage(int initiatorSiteId,
                        int coordinatorSiteId,
                        long txnId,
                        boolean isReadOnly,
                        long[] fragmentIds,
                        int[] outputDepIds,
                        ByteBuffer[] parameterSets,
                        boolean isFinal)
```
where first 4 parameters and the last one are all ready before the whole routine.

If a transaction is of type one-shot, it can be divided into several fragments, and all fragments need to be sent only once (no dependencies), thus, three parameters unknown above can be got from:
```
	fragmentIds – from PlanFragment of Statement, it’s unique
	outputDepIds – empty
	parameterSets – built in voltQueueSQL()
```

However, after executing voltQueueSQL(), the procedure is already started (actually is running the first workunit) in current system.

But it might be possible to build it when the client request coming, if we can map between SQL statements and parameter list in run() (Map<Statement, ParamList>), and we already know number of parameters of each statement in the procedure in the deployment phase, and the value of parameter are known when the request coming.

Now the problem is how to map between SQL statement and parameter list in run(). Java reflection class Method only gives parameter’s type, so it seems we only can map them iff forced to code parameters in order, for example,
```
	void run(param1, param2, param3, param4, param5) {
		stmt1(param1, param2);
		stmt2(param3);
		stmt3(param4, param5);
        }
```




# One Shot Transaction Defenition – from the email discussion #

  * Definition: transaction with a single batch of SQL (one or more statements with no Java in between).

  * Source: http://danweinreb.org/blog/voltdb-versus-nosql

  * “Re transaction types: VoltDB asks the developer to classify transactions as either single-partition or multi-partition. We do support fully general transactions with multiple round trips, but they are of course, much slower. One thing we allow the developer to to is to tag a batch of SQL as the “final” batch for a transaction. This hint allows VoltDB to combine some cleanup work and can eliminate a round trip on the network. For a transaction with a single batch of SQL (one or more statements with no Java in between), this hint allows for the transaction to often complete in one round trip. These are the “one-shot” transactions we used to talk about.”

  * o more than one voltExecuteSQL() might exist in the stored procedure of a “one-shot” transaction? No, multiple voltQueueSQL() can exist in a "one-shot" transaction, but only one "voltExecuteSQL()".